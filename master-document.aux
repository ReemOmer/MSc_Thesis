\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {chapter}{Abstract}{i}{chapter*.1}}
\citation{Survey}
\citation{Kurukshetra}
\citation{Clark,Knorr}
\citation{Silvia}
\citation{Barnett}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Outlier}
\citation{Outlier}
\citation{Kurukshetra}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Defining Outliers}{1}{section.1.1}}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Survey}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Observations in 2-dimensional space \citep  {Kurukshetra}.\relax }}{2}{figure.caption.4}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{outlier}{{1.1}{2}{Observations in 2-dimensional space \citep {Kurukshetra}.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Outlier Detection}{2}{section.1.2}}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Kurukshetra}
\citation{Songwon}
\citation{Kurukshetra}
\citation{Survey}
\@writefile{toc}{\contentsline {section}{\numberline {1.3}Outlier Detection Applications}{3}{section.1.3}}
\citation{Kurukshetra}
\citation{Survey}
\citation{Andrew}
\citation{Andrew}
\citation{Andrew}
\citation{Goldstein}
\@writefile{toc}{\contentsline {section}{\numberline {1.4}Machine Learning}{4}{section.1.4}}
\citation{Silvia}
\citation{Markus}
\citation{LOF}
\citation{LOF}
\citation{LOF}
\citation{Markus}
\citation{Knorr}
\citation{Markus}
\citation{Markus}
\citation{Markus}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Local Outlier Factor}{5}{chapter.2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{LOF}{{2}{5}{Local Outlier Factor}{chapter.2}{}}
\newlabel{Local_Outlier_Factor}{{2}{5}{Local Outlier Factor}{chapter.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Point A has a much lower density than its neighbors \citep  {LOF}.\relax }}{5}{figure.caption.5}}
\newlabel{LOF-MD2}{{2.1}{5}{Point A has a much lower density than its neighbors \citep {LOF}.\relax }{figure.caption.5}{}}
\newlabel{LOF1}{{2.0.1}{5}{Global Outlier in dataset $D$}{subsection.2.0.1}{}}
\newlabel{LOF2}{{2.0.2}{5}{$k$-Distance of an object $p$}{subsection.2.0.2}{}}
\newlabel{a}{{2.0.1}{5}{$k$-Distance of an object $p$}{equation.2.0.1}{}}
\citation{LOF}
\citation{Markus}
\citation{Mathew}
\citation{LOF}
\citation{LOF}
\citation{LOF}
\citation{Markus}
\citation{Hongyin}
\citation{Markus}
\newlabel{LOF3}{{2.0.3}{6}{$k$-Distance Neighbourhood of an object $p$}{subsection.2.0.3}{}}
\newlabel{b}{{2.0.2}{6}{$k$-Distance Neighbourhood of an object $p$}{equation.2.0.2}{}}
\newlabel{LOF4}{{2.0.4}{6}{Reachability Distance of an Object $p$ with respect to object $o$}{subsection.2.0.4}{}}
\newlabel{c}{{2.0.3}{6}{Reachability Distance of an Object $p$ with respect to object $o$}{equation.2.0.3}{}}
\newlabel{LOF5}{{2.0.5}{6}{Local Reachability Density of an object $p$}{subsection.2.0.5}{}}
\newlabel{d}{{2.0.4}{6}{Local Reachability Density of an object $p$}{equation.2.0.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Reachability density ($k$=3) of two points $p_1$ and $p_2$ w.r.t. point $o$ \citep  {LOF}.\relax }}{6}{figure.caption.6}}
\newlabel{reach_dist}{{2.2}{6}{Reachability density ($k$=3) of two points $p_1$ and $p_2$ w.r.t. point $o$ \citep {LOF}.\relax }{figure.caption.6}{}}
\newlabel{LOF6}{{2.0.6}{6}{Local Outlier Factor for an object $p$}{subsection.2.0.6}{}}
\newlabel{e}{{2.0.5}{6}{Local Outlier Factor for an object $p$}{equation.2.0.5}{}}
\citation{Markus}
\citation{Markus}
\citation{Markus}
\citation{Markus}
\citation{Markus}
\citation{Markus}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Properties of LOF}{7}{section.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}\unskip \nobreakspace  {}LOF for Observations Deep in a Cluster:\nobreakspace  {}}{7}{subsection.2.1.1}}
\newlabel{lem1}{{2.1.2}{7}{}{subsection.2.1.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}\unskip \nobreakspace  {}Upper and Lower Bound on LOF:\nobreakspace  {}}{7}{subsection.2.1.3}}
\newlabel{thm1}{{2.1.4}{7}{}{subsection.2.1.4}{}}
\citation{Markus}
\citation{Malak}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.5}\unskip \nobreakspace  {}Bounds Tightness:\nobreakspace  {}}{8}{subsection.2.1.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.6}\unskip \nobreakspace  {}impact of $k$ on LOF:\nobreakspace  {}}{8}{subsection.2.1.6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}LOF Algorithm}{8}{section.2.2}}
\pgfsyspdfmark {pgfid1}{6499494}{33679363}
\pgfsyspdfmark {pgfid2}{7122436}{31005493}
\pgfsyspdfmark {pgfid3}{8077294}{29222913}
\newlabel{loffor}{{9}{8}{LOF Algorithm}{section.2.2}{}}
\newlabel{loffor}{{10}{8}{LOF Algorithm}{section.2.2}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces Local Outlier Factor algorithm\relax }}{8}{algorithm.1}}
\newlabel{lof}{{1}{8}{Local Outlier Factor algorithm\relax }{algorithm.1}{}}
\citation{Silvia}
\citation{Maimon}
\citation{Roemer}
\citation{SVM}
\citation{Maimon}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Support Vector Machines}{9}{chapter.3}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Support_Vector_Machine}{{3}{9}{Support Vector Machines}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}Basics of SVMs}{9}{section.3.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces The possible hyperplanes with its different distances from the observations, some hyperplanes are close to one observations of the classes.\relax }}{9}{figure.caption.7}}
\newlabel{hyperplanes}{{3.1}{9}{The possible hyperplanes with its different distances from the observations, some hyperplanes are close to one observations of the classes.\relax }{figure.caption.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces The optimal hyperplane the one that has maximum distances between the classes, it shouldn't also biased to one side.\relax }}{9}{figure.caption.7}}
\newlabel{maxHyperplane}{{3.2}{9}{The optimal hyperplane the one that has maximum distances between the classes, it shouldn't also biased to one side.\relax }{figure.caption.7}{}}
\citation{Maimon}
\citation{Maimon}
\citation{Maimon}
\newlabel{equ-3-1}{{3.1.1}{10}{Basics of SVMs}{equation.3.1.1}{}}
\newlabel{equ-3-2}{{3.1.2}{10}{Basics of SVMs}{equation.3.1.2}{}}
\newlabel{equ-3-3}{{3.1.3}{10}{Basics of SVMs}{equation.3.1.3}{}}
\newlabel{equ-3-4}{{3.1.4}{10}{Basics of SVMs}{equation.3.1.4}{}}
\newlabel{equ-3-5}{{3.1.6}{10}{Basics of SVMs}{equation.3.1.6}{}}
\newlabel{equ-3-6}{{3.1.7}{10}{Basics of SVMs}{equation.3.1.7}{}}
\newlabel{equ-3-7}{{3.1.8}{10}{Basics of SVMs}{equation.3.1.8}{}}
\newlabel{equ-3-8}{{3.1.9}{10}{Basics of SVMs}{equation.3.1.9}{}}
\citation{Maimon}
\citation{Hyperplane}
\citation{Hyperplane}
\citation{Thuso}
\newlabel{equ-3-9}{{3.1.10}{11}{Basics of SVMs}{equation.3.1.10}{}}
\newlabel{equ-3-10}{{3.1.11}{11}{Basics of SVMs}{equation.3.1.11}{}}
\newlabel{equ-3-11}{{3.1.12}{11}{Basics of SVMs}{equation.3.1.12}{}}
\newlabel{equ-3-12}{{3.1.13}{11}{Basics of SVMs}{equation.3.1.13}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Kernel function $K$ projected the observations from input space to feature space \citep  {Hyperplane}.\relax }}{11}{figure.caption.8}}
\newlabel{hyperplane-grayscale}{{3.3}{11}{Kernel function $K$ projected the observations from input space to feature space \citep {Hyperplane}.\relax }{figure.caption.8}{}}
\citation{OCSVM}
\citation{Maimon}
\citation{Thuso}
\citation{Maimon}
\newlabel{equ-3-13}{{3.1.14}{12}{Basics of SVMs}{equation.3.1.14}{}}
\newlabel{equ-3-14}{{3.1.15}{12}{Basics of SVMs}{equation.3.1.15}{}}
\newlabel{equ-3-15}{{3.1.16}{12}{Basics of SVMs}{equation.3.1.16}{}}
\newlabel{equ-3-16}{{3.1.17}{12}{Basics of SVMs}{equation.3.1.17}{}}
\newlabel{equ-3-17}{{3.1.18}{12}{Basics of SVMs}{equation.3.1.18}{}}
\citation{Roemer}
\newlabel{equ-3-18}{{3.1.19}{13}{Basics of SVMs}{equation.3.1.19}{}}
\newlabel{equ-3-19}{{3.1.20}{13}{Basics of SVMs}{equation.3.1.20}{}}
\newlabel{equ-3-20}{{3.1.21}{13}{Basics of SVMs}{equation.3.1.21}{}}
\newlabel{equ-3-21}{{3.1.22}{13}{Basics of SVMs}{equation.3.1.22}{}}
\newlabel{equ-3-22}{{3.1.23}{13}{Basics of SVMs}{equation.3.1.23}{}}
\newlabel{equ-3-23}{{3.1.24}{13}{Basics of SVMs}{equation.3.1.24}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}One Class Support Vector Machine}{13}{section.3.2}}
\newlabel{OCSVM}{{3.2}{13}{One Class Support Vector Machine}{section.3.2}{}}
\citation{Scholkopf}
\citation{OCSVM}
\citation{Scholkopf}
\citation{David}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces One class SVM, whereby the hyperplane separates the normal observations class 1 from anything else (outliers) class -1.\relax }}{14}{figure.caption.9}}
\newlabel{OSVM1}{{3.4}{14}{One class SVM, whereby the hyperplane separates the normal observations class 1 from anything else (outliers) class -1.\relax }{figure.caption.9}{}}
\citation{RBFkernel}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Experiment}{15}{chapter.4}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Experiment}{{4}{15}{Experiment}{chapter.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Methodology}{15}{section.4.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Methodology for comparing the performance of LOF and OCSVM algorithms on detecting fraud transaction on a credit card transactions dataset.\relax }}{16}{figure.caption.10}}
\newlabel{workflow}{{4.1}{16}{Methodology for comparing the performance of LOF and OCSVM algorithms on detecting fraud transaction on a credit card transactions dataset.\relax }{figure.caption.10}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}Input Data}{16}{section.4.2}}
\citation{Confusion}
\citation{ROC}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Normal and fraud transactions amounts distribution of a credit card fraud dataset\relax }}{17}{figure.caption.11}}
\newlabel{distribution}{{4.2}{17}{Normal and fraud transactions amounts distribution of a credit card fraud dataset\relax }{figure.caption.11}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Observations division in LOF and OCSVM. LOF takes all the observations in training and testing while OCSVM divide the dataset into training data and testing data.\relax }}{17}{table.caption.12}}
\newlabel{tab:mylabel}{{4.1}{17}{Observations division in LOF and OCSVM. LOF takes all the observations in training and testing while OCSVM divide the dataset into training data and testing data.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Evaluation Metrics}{17}{section.4.3}}
\newlabel{evaluation_matrices}{{4.3}{17}{Evaluation Metrics}{section.4.3}{}}
\citation{ROC}
\citation{AUROC}
\citation{AUROC}
\citation{AUROC}
\citation{AUC}
\citation{AUROC}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Confusion matrix components. Positive sign refers to normal observations and minus sign refers to outliers. The components obtain by comparing actual to predicted values.\relax }}{18}{figure.caption.13}}
\newlabel{confusion-matrix}{{4.3}{18}{Confusion matrix components. Positive sign refers to normal observations and minus sign refers to outliers. The components obtain by comparing actual to predicted values.\relax }{figure.caption.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}Analysis and Results}{19}{section.4.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces LOF results of 2 features with $k=20$.\relax }}{19}{figure.caption.14}}
\newlabel{LOF2D}{{4.4}{19}{LOF results of 2 features\\with $k=20$.\relax }{figure.caption.14}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces OCSVM results of 2 features with $\nu $=0.1, $\gamma $=0.1 and RBF kernel.\relax }}{19}{figure.caption.14}}
\newlabel{OCSVM2D}{{4.5}{19}{OCSVM results of 2 features with $\nu $=0.1, $\gamma $=0.1 and RBF kernel.\relax }{figure.caption.14}{}}
\citation{AUROC}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces The results of LOF are truncated to 4 digits. When $k$ value increases TPR increases and FPR decreases.\relax }}{20}{table.caption.15}}
\newlabel{tab:myLOF}{{4.2}{20}{The results of LOF are truncated to 4 digits. When $k$ value increases TPR increases and FPR decreases.\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces The results of OCSVM are truncated to 4 digits. The increase in $\nu $ value and the decrease in $\gamma $, decreases both TPR and FPR values.\relax }}{20}{table.caption.16}}
\newlabel{tab:myOCSVM}{{4.3}{20}{The results of OCSVM are truncated to 4 digits. The increase in $\nu $ value and the decrease in $\gamma $, decreases both TPR and FPR values.\relax }{table.caption.16}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces LOF model results when parameter  value $k$=10 gives the highest AUC percentage.\relax }}{21}{figure.caption.17}}
\newlabel{LOF_TPR_FPR}{{4.6}{21}{LOF model results when parameter \\value $k$=10 gives the highest AUC percentage.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Highest AUC (94$\%$) is obtained by setting the parameters $\nu $=0.09 and $\gamma $=0.0001.\relax }}{21}{figure.caption.17}}
\newlabel{OCSVM_TPR_FPR}{{4.7}{21}{Highest AUC (94$\%$) is obtained by setting the parameters $\nu $=0.09 and $\gamma $=0.0001.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.5}Discussion}{21}{section.4.5}}
\citation{*}
\bibstyle{abbrvnat}
\bibdata{references}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Conclusions}{22}{chapter.5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{Conclusion}{{5}{22}{Conclusions}{chapter.5}{}}
\bibcite{AUC}{{1}{Accessed May 2017}{{AUC}}{{}}}
\bibcite{AUROC}{{2}{Accessed May 2017}{{AUR}}{{}}}
\bibcite{Confusion}{{3}{Accessed May 2017}{{Con}}{{}}}
\bibcite{Hyperplane}{{4}{Accessed May 2017}{{Hyp}}{{}}}
\bibcite{OCSVM}{{5}{Accessed May 2017}{{OCS}}{{}}}
\bibcite{RBFkernel}{{6}{Accessed May 2017}{{RBF}}{{}}}
\bibcite{ROC}{{7}{Accessed May 2017}{{ROC}}{{}}}
\bibcite{SVM}{{8}{Accessed May 2017}{{SVM}}{{}}}
\bibcite{Anomlay}{{9}{}{{Anomlay}}{{}}}
\bibcite{Nicholas}{{10}{2008}{{Arcolano and Rudoy}}{{}}}
\bibcite{Barnett}{{11}{1994}{{Barnett and Lewis}}{{}}}
\bibcite{Markus}{{12}{2000}{{Breunig et~al.}}{{Breunig, Kriegel, Ng, and Sander}}}
\bibcite{Survey}{{13}{2009}{{Chandola et~al.}}{{Chandola, Banerjee, and Kumar}}}
\bibcite{Hongyin}{{14}{2005}{{Cui}}{{}}}
\bibcite{Goldstein}{{15}{2016}{{Goldstein~M}}{{}}}
\bibcite{Edwin}{{16}{2002}{{Knorr}}{{}}}
\bibcite{Knorr}{{17}{1998}{{Knox and Ng}}{{}}}
\bibcite{LOF}{{18}{}{{LOF}}{{}}}
\bibcite{Malak}{{19}{2010}{{Malak~Alshawabkeh}}{{}}}
\bibcite{Mathew}{{20}{2016}{{Mathew X.~Ma and Liu}}{{}}}
\bibcite{Thuso}{{21}{2014}{{Modise}}{{}}}
\bibcite{Clark}{{22}{1993}{{MR~Tight and Clark}}{{}}}
\bibcite{Edgar}{{23}{2005}{{na and Lozano}}{{}}}
\bibcite{Andrew}{{24}{2017}{{Ng}}{{}}}
\bibcite{NIST}{{25}{2003}{{NIST}}{{}}}
\bibcite{Maimon}{{26}{2010}{{Oded~Maimon}}{{}}}
\bibcite{Outlier}{{27}{}{{Outlier}}{{}}}
\bibcite{Scholkopf}{{28}{1998}{{Scholkopf et~al.}}{{Scholkopf, Williamson, Smola, Shawe-Taylor, and Platt}}}
\bibcite{SCM}{{29}{}{{SCM}}{{}}}
\bibcite{Songwon}{{30}{2006}{{Seo}}{{}}}
\bibcite{Silvia}{{31}{2008}{{Silvia~Cateni and Vannucci}}{{}}}
\bibcite{Kurukshetra}{{32}{2012}{{Singh and Upadhyaya}}{{}}}
\bibcite{David}{{33}{2004}{{Tax and Duin}}{{}}}
\bibcite{Roemer}{{34}{Accessed April 2017}{{Vlasveld}}{{}}}
\@writefile{toc}{\contentsline {chapter}{References}{24}{chapter*.18}}
